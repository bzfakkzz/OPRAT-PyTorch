import random
import shutil
import time

import troubleshooter as ts
from typing import List, Dict, Set, Tuple, Any
import numpy as np
import torch
import mindspore as ms
from mindspore import context

from Compare.Compare import InferAndCompare, InferAndCompareSingleModel
from Compare.Count import CountInSeq
from models import convert_weights
from attacks import generate_adversarial_samples, create_pytorch_classifier
from data.getdata import generate_random_data
import torch

import os
import csv
import sys

current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)
from config import TORCH_MODEL, MS_MODEL, model_map, NUM_CLASSES, INPUTSHAPE

# è®¾ç½®éšæœºç§å­ç¡®ä¿å¯å¤ç°
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)

# context.set_context(mode=context.PYNATIVE_MODE, device_target="GPU")
device = torch.device('cuda')
os.makedirs('adversarial_samples', exist_ok=True)
os.makedirs('adversarial_samples/seed_data', exist_ok=True)
os.makedirs('model_robustness', exist_ok=True)
os.makedirs('model_robustness/pytorch', exist_ok=True)

# åŸºç¡€ç›®å½•
base_ad_dir = "adversarial_samples"
base_seed_dir = "adversarial_samples/seed_data"
base_robustness_dir = "model_robustness/pytorch"

for Torch_model, Mindspore_model, input_shape in zip(TORCH_MODEL, MS_MODEL, INPUTSHAPE):
    # ä¸ºå½“å‰æ¨¡å‹åˆ›å»ºä¸“å±ç›®å½•
    model_name = Torch_model  # ä½¿ç”¨æ¨¡å‹åç§°ä½œä¸ºç›®å½•å
    ad_dir = os.path.join(base_ad_dir, model_name)
    seed_dir = os.path.join(base_seed_dir, model_name)
    robustness_dir = os.path.join(base_robustness_dir, model_name)
    
    # åˆ›å»ºæ¨¡å‹ä¸“å±ç›®å½•
    os.makedirs(ad_dir, exist_ok=True)
    os.makedirs(seed_dir, exist_ok=True)
    os.makedirs(robustness_dir, exist_ok=True)
    
    # åˆ›å»ºæ¨¡å‹ä¸“å±æ—¥å¿—æ–‡ä»¶
    attack_info_file = os.path.join(ad_dir, "attack_generation_info.txt")
    with open(attack_info_file, 'w') as info_file:
        info_file.write("Generation\tAttack\tSeed_Data_Path\n")
    
    # åˆ›å»ºæ¨¡å‹ä¸“å±ç»“æœæ–‡ä»¶
    robustness_stats_file = os.path.join(robustness_dir, "robustness_stats.csv")
    robustness_details_file = os.path.join(robustness_dir, "robustness_details.csv")
    
    with open(robustness_stats_file, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(["Round", "Succ", "All", "Prob"])
    
    with open(robustness_details_file, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(["Round", "Index", "True Label", "Predict Label"])
    
    # æ¨¡å‹ä¸“å±å¯¹æŠ—æ ·æœ¬ç›®å½•
    model_ad_dir = ad_dir
    
    print("-----------------------------------------------------------------------------\n")
    print(f"{model_name}æ¨¡å‹è¿è¡Œä¸­....")
    print("-----------------------------------------------------------------------------\n")

    # å‡†å¤‡
    attack_techniques = ['FGM', 'PGD', 'CW', 'DeepFool', 'Universal']
    test_data = generate_random_data(model_map[input_shape], 10)
    torch_model = model_map[Torch_model](num_classes=NUM_CLASSES)
    torch_model.cuda(device)
    execution_rounds = 100
    Robustness = []

    # ä¿å­˜åˆå§‹ç§å­æ•°æ®
    initial_seed_path = os.path.join(seed_dir, "initial_seed_data.npy")
    np.save(initial_seed_path, test_data.numpy())

    # è®°å½•åˆå§‹ç§å­æ•°æ®ä¿¡æ¯
    with open(attack_info_file, 'a') as info_file:
        info_file.write(f"initial\t-\t{initial_seed_path}\n")

    # åˆå§‹åŒ–ç»Ÿè®¡å­—å…¸
    T = {a: 0 for a in attack_techniques}
    H = {a: 0 for a in attack_techniques}
    S = []
    D_diff = []

    print("è¿›è¡Œåˆå§‹åŒ–...")
    for attack in attack_techniques:
        print(f"ç°åœ¨æ”»å‡»çš„æ˜¯{attack}....")
        start = time.perf_counter()
        classifier = create_pytorch_classifier(torch_model, model_map[input_shape], NUM_CLASSES)
        attack_data = generate_adversarial_samples(attack, classifier, test_data)
        end = time.perf_counter()
        print(f"è¿è¡Œæ—¶é—´: {end - start:.6f} ç§’")

        cnt, diff_indices, original_pred_labels, attack_pred_labels = InferAndCompareSingleModel(
            torch_model, test_data, attack_data, device, model_ad_dir, 0, attack)
        D_new = attack_data[diff_indices]

        T[attack] = cnt
        H[attack] = 0
        D_diff.extend(D_new)

        with open(attack_info_file, 'a') as info_file:
            info_file.write(f"0\t{attack}\t{initial_seed_path}\n")
    print("åˆå§‹åŒ–ç»“æŸ...")

    for execution_round in range(execution_rounds):
        test_data = generate_random_data(model_map[input_shape], 10)
        gen = execution_round + 1
        seed_path = os.path.join(seed_dir, f"gen_{gen}_seed_data.npy")
        np.save(seed_path, test_data.numpy())

        with open(attack_info_file, 'a') as info_file:
            info_file.write(f"{gen}\t-\t{seed_path}\n")

        print(f"è¿™æ˜¯ç¬¬{gen}è½®æ¨ç†...")
        G = [0 for attack in attack_techniques]
        for j in range(len(attack_techniques)):
            G[j] = T[attack_techniques[j]] - H[attack_techniques[j]]
        
        G_max = max(G)
        C = []
        for i, g in enumerate(G):
            if g == G_max:
                C.append(i)

        F_min, c = CountInSeq(S, C, attack_techniques)
        i = random.choice(c)
        attack = attack_techniques[i]
        print(f"è¦è¿›è¡Œçš„æ˜¯{attack}æ”»å‡»...")
        S.append(attack)

        classifier = create_pytorch_classifier(torch_model, model_map[input_shape], NUM_CLASSES)
        attack_data = generate_adversarial_samples(attack, classifier, test_data)

        cnt, diff_indices, original_pred_labels, attack_pred_labels = InferAndCompareSingleModel(
            torch_model, test_data, attack_data, device, model_ad_dir, gen, attack)
        D_new = attack_data[diff_indices]
        cnt1 = cnt
        cnt2 = len(attack_data)

        H[attack] = T[attack]
        T[attack] = cnt
        D_diff.extend(D_new)

        with open(attack_info_file, 'a') as info_file:
            info_file.write(f"{gen}\t{attack}\t{seed_path}\n")

        with open(robustness_stats_file, 'a', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow([f"{gen}", cnt1, cnt2, 1.0 * cnt1 / cnt2])

        with open(robustness_details_file, 'a', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            for i in diff_indices:
                writer.writerow([f"{gen}", i, original_pred_labels[i], attack_pred_labels[i]])

    print("æ¨ç†è½®æ¬¡ç»“æŸ...")
    
    # for execution_round in range(execution_rounds):
    #     print(f"è¿™æ˜¯ç¬¬{execution_round+1}è½®æ¨ç†...")
    #     G=[0 for attack in attack_techniques]
    #     for j in range(len(attack_techniques)):
    #         G[j]=T[attack_techniques[j]]-H[attack_techniques[j]]
    #     # G_max â† max(G); C â†{j|G[j]=Gmax}
    #     G_max=max(G)
    #     C=[]
    #     for i,g in enumerate(G):
    #         if g==G_max:
    #             C.append(i)

    #     # F_min â†min{ CountInSeq(S,aj) | je C}
    #     # C'â†{j C | CountInSeq(S,aÂ¡) = F_min }
    #     F_min,c=CountInSeq(S,C,attack_techniques)
    #     #i<-randomchoice(C');arâ†F_min[i]
    #     i=random.choice(c)
    #     attack=attack_techniques[i]
    #     print(f"è¦è¿›è¡Œçš„æ˜¯{attack}æ”»å‡»...")
    #     #add ar to S
    #     S.append(attack)

    #     #D_attack â†- DataAttack(D_test, aj)
    #     classifier = create_pytorch_classifier(torch_model, model_map[input_shape], NUM_CLASSES)
    #     attack_data = generate_adversarial_samples(attack, classifier, test_data)

    #     #t, ğ’Ÿ_new â† InferAndCompare(Mâ‚, Mâ‚‚, ğ’Ÿ_attack)
    #     t,D_new=InferAndCompare(torch_model,ms_model,attack_data)

    #     #H[a,]â† T[a,]; T[ar]â† tnew
    #     H[attack]=T[attack]
    #     T[attack]=t
    #     #D_diff â† D_diff U D_new
    #     D_diff.extend(D_new)

    #     torch_diff, ms_diff, torch_true_labels, torch_pred_labels, ms_true_labels, ms_pred_labels = GetCmp(
    #         torch_model, ms_model, test_data, attack_data)
    #     with open("model_robustness/pytorch_robustness_test.csv",'w',newline='',encoding='utf-8')as f:
    #         writer=csv.writer(f)
    #         for i in torch_diff:
    #             writer.writerow([f"{execution_round+1}", torch_true_labels[i], torch_pred_labels[i]])
    #     with open("model_robustness/mindspore_robustness_test.csv",'w',newline='',encoding='utf-8')as f:
    #         writer=csv.writer(f)
    #         for i in torch_diff:
    #             writer.writerow([f"{execution_round+1}", ms_true_labels[i], ms_pred_labels[i]])
            
    # print("æ¨ç†è½®æ¬¡ç»“æŸ...")
    # with open('out.txt', 'w', encoding='utf-8') as f:
    #     for item in D_diff:
    #         f.write(f"{item}\n")

    # print("å±‚æ¬¡æ¯”è¾ƒ")
    # os.makedirs(f"{input_shape}_output",exist_ok=True)
    # os.makedirs(f"{input_shape}_results",exist_ok=True)
    # count=0
    # for input in D_diff:
    #     print(f"ç¬¬{count+1}ç»„æ¯”è¾ƒä¸­...")
    #     if count%10!=0:
    #         count=count+1
    #         continue   #å†…å­˜ä¸å¤Ÿäº†ï¼Œåªèƒ½æ¯10è½®è®°å½•ä¸€æ¬¡
    #     #torchå±‚è¾“å‡º
    #     torch_model.eval()
    #     test_torch = torch.from_numpy(input).float()
    #     ts.migrator.api_dump_init(
    #         torch_model,
    #         output_path=f"{input_shape}_output/torch_test_dump{count}",
    #         retain_backward=False
    #     )
    #     with torch.no_grad():
    #         ts.migrator.api_dump_start()
    #         torch_output = torch_model(test_torch)
    #         ts.migrator.api_dump_stop()

    #     #mindsporeå±‚è¾“å‡º
    #     ms_model.set_train(False)
    #     test_ms = ms.Tensor(input, dtype=ms.float32)
    #     ts.migrator.api_dump_init(
    #         ms_model,
    #         output_path=f"{input_shape}_output/ms_test_dump{count}",
    #         retain_backward=False
    #     )
    #     ts.migrator.api_dump_start()
    #     ms_output = ms_model(test_ms)
    #     ts.migrator.api_dump_stop()

    #     # ä½¿ç”¨ TroubleShooter çš„æ¯”è¾ƒåŠŸèƒ½
    #     ts.migrator.api_dump_compare(
    #         f'{input_shape}_output/ms_test_dump{count}',
    #         f'{input_shape}_output/torch_test_dump{count}',
    #         output_path=f'{input_shape}_results/comparison_results{count}'
    #     )

    #     shutil.rmtree(f'{input_shape}_output/ms_test_dump{count}')
    #     shutil.rmtree(f'{input_shape}_output/torch_test_dump{count}')
    #     count=count+1

    # shutil.rmtree(f'{input_shape}_output')